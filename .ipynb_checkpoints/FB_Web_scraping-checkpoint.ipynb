{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 17/01/2018\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import pprint\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set since 3000 recursions, for post with >= 25000 comments\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlopen, Request\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen, Request\n",
    "\n",
    "app_id = \"1279153855620167\"\n",
    "app_secret = \"ac4cb31ea1286f1ee4bb2ed75233e7ca\"  # DO NOT SHARE WITH ANYONE!\n",
    "# !!GOOD BOTH FOR PAGE AND FOR GROUPS!!\n",
    "page_id = \"laanews\" \n",
    "#page: https://www.facebook.com/laanews/posts/1311167095711069?__tn__=H-R\n",
    "num_post = 0\n",
    "num_comments = 0\n",
    "num_comm_per_page = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_num_post(value):\n",
    "    global num_post\n",
    "    num_post = num_post + value\n",
    "\n",
    "def add_num_comments(value):\n",
    "    global num_comments\n",
    "    num_comments = num_comments + value\n",
    "\n",
    "def request_until_succeed(url):\n",
    "    req = Request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try:\n",
    "            response = urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5)\n",
    "\n",
    "            print(\"Error for URL {}: {}\".format(url, datetime.datetime.now()))\n",
    "            print(\"Retrying.\")\n",
    "\n",
    "    return response.read()\n",
    "\n",
    "\n",
    "def writeFile(path, name, text):\n",
    "    write_file = open(path + name,\"w+\")\n",
    "    write_file.write(text)\n",
    "    write_file.close()\n",
    "\n",
    "# The function for taking comments is recursive. Comments are taken 25 at a time.\n",
    "# There is a maximum number of recursion for the python interpreter (= 1000).\n",
    "# If the post has a number of comments > 25000 (25000/25 = 1000), our interpreter crash.\n",
    "# This function is useful for dynamically increase the maximum number of recursions possible by the Python interpreter\n",
    "def set_recursion_limit(total_comments):\n",
    "    for key, value in total_comments.iteritems() :\n",
    "        if key==\"total_count\":\n",
    "            sys.setrecursionlimit( value/num_comm_per_page )\n",
    "\n",
    "####################################################################\n",
    "#                       SCRAPING POSTs                             #\n",
    "####################################################################\n",
    "\n",
    "# first request will be of the type:\n",
    "# https://graph.facebook.com/v2.11/page_id/posts?access_token=....\n",
    "# then, will be gather all the values next in the json file in order to do at the next request\n",
    "def scrape_first_posts_in_page(page_id, access_token):\n",
    "    base = \"https://graph.facebook.com/v2.11/\"\n",
    "    parameters = \"&access_token={}\".format(access_token)\n",
    "    fields = \"?fields=posts\"\n",
    "    num_page = 1\n",
    "\n",
    "    url = base + page_id + fields + parameters\n",
    "    #print(url)\n",
    "    print(\"\\n scraping posts in page: \" + str(num_page))\n",
    "    json_downloaded = request_until_succeed(url)\n",
    "    data = json.loads(json_downloaded)['posts']['data'] # Json(casted in list) data from our request\n",
    "    next_post = json.loads(json_downloaded)['posts']['paging'] # this are used for take 'next' element in the dictionary\n",
    "    for key, value in next_post.iteritems() :\n",
    "        if key==\"next\":\n",
    "            next_value = value\n",
    "\n",
    "    writeFile(\"./posts/\", str(num_page) + \".next_value.txt\", next_value)\n",
    "    print(\"\\n writing \"+ str(num_page) +\" next_value\")\n",
    "\n",
    "    loops_for_scraping_comments(num_page, data)\n",
    "\n",
    "    scrape_all_posts_in_page(next_value, num_page + 1)\n",
    "\n",
    "def scrape_all_posts_in_page(url, num_page):\n",
    "    json_downloaded = request_until_succeed(url)\n",
    "    data = json.loads(json_downloaded)['data'] # Json(casted in dictionary) data from our request\n",
    "    next_post = json.loads(json_downloaded)['paging'] # this are used for take 'next' element in the dictionary\n",
    "\n",
    "    #pp = pprint.PrettyPrinter(indent=2)\n",
    "    #pp.pprint(next_post)\n",
    "    for key, value in next_post.iteritems() :\n",
    "        if key==\"next\":\n",
    "            next_value = value\n",
    "            writeFile(\"./posts/\", str(num_page) + \".next_value\", value)\n",
    "            print(\"\\n writing \"+ str(num_page) +\" next_value\")\n",
    "\n",
    "    print(\"\\n scraping posts in page: \" + str(num_page))\n",
    "\n",
    "    loops_for_scraping_comments(num_page, data)\n",
    "\n",
    "    scrape_all_posts_in_page(next_value, num_page + 1)\n",
    "\n",
    "####################################################################\n",
    "#                       SCRAPE POST'S COMMENTS                     #\n",
    "####################################################################\n",
    "\n",
    "# function for scrape single post's comments\n",
    "def loops_for_scraping_comments(num_page, data):\n",
    "    # retrieve data, message and id (useful for querying the comments)\n",
    "    extension=\".json\"\n",
    "    i = 0\n",
    "    #print(len(data))\n",
    "    #count num_post\n",
    "    add_num_post(len(data))\n",
    "\n",
    "    while (i < len(data)):\n",
    "        print(\"\\n   scraping post \" + str(i + 1)  + \" in page: \" + str(num_page))\n",
    "\n",
    "        created_time = data[i]['created_time']\n",
    "\n",
    "        # use get method over the dictionary because the comment couldn't exist and Facebook doesn't generate the corresponding item in the Json file\n",
    "        if data[i].get('message') is None:\n",
    "            message = \"\"\n",
    "        else:\n",
    "            message = data[i].get('message').encode(\"utf-8\")\n",
    "\n",
    "        id_post = data[i]['id']\n",
    "        scrape_starttime = datetime.datetime.now()\n",
    "        comments = scrape_first_comments_from_post_id(id_post, access_token)\n",
    "        print(\"   Done! Comment Processed in {}\".format(datetime.datetime.now() - scrape_starttime))\n",
    "\n",
    "        name_file =  str(created_time).replace(':','.') + \"page_\" + str(num_page) + \"_posts\" + str(i + 1)\n",
    "        writeFile(name_file + extension, str(created_time) + \"\\n\\n\" + str(message) + \"\\n\\n\" + str(id_post) + \"\\n\\n\" + str(comments) + \"\\n\\n\")\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "def scrape_first_comments_from_post_id(post_id, access_token):\n",
    "    # with filter=stream should also gather the aswers to comments, but it seems doesn't work\n",
    "    # https://graph.facebook.com/v2.11/post_id/comments?filter=stream&summary=true&access_token=2081983152047773|cUqdwRV6VnEZBTwAwmv5wdBQEBw\n",
    "    base = \"https://graph.facebook.com/v2.11/\"\n",
    "    parameters = \"&access_token={}\".format(access_token)\n",
    "    fields = \"/comments?filter=stream&summary=true\"\n",
    "\n",
    "    scr_data = []\n",
    "    url= base + post_id + fields + parameters\n",
    "    json_downloaded = request_until_succeed(url)\n",
    "\n",
    "    data = json.loads(json_downloaded)['data']\n",
    "\n",
    "    if json.loads(json_downloaded).get('paging') is None:\n",
    "        next_post = {}\n",
    "    else:\n",
    "        next_post = json.loads(json_downloaded).get('paging')\n",
    "\n",
    "    total_comments = json.loads(json_downloaded)['summary']\n",
    "\n",
    "    #set_recursion_limit(total_comments)\n",
    "\n",
    "    comment_count = 0\n",
    "    for count in data:\n",
    "        comment_count += 1\n",
    "\n",
    "    #count comments\n",
    "    add_num_comments(comment_count)\n",
    "\n",
    "    #search next post url\n",
    "    for key, value in next_post.iteritems() :\n",
    "        if key==\"next\":\n",
    "            scr_data = scrape_all_comments_from_post_id(value)\n",
    "\n",
    "    return data + scr_data\n",
    "\n",
    "def scrape_all_comments_from_post_id(url):\n",
    "    scr_data = []\n",
    "    json_downloaded = request_until_succeed(url)\n",
    "\n",
    "    data = json.loads(json_downloaded)['data'] # Json(casted in dictionary) data from our request\n",
    "    next_post = json.loads(json_downloaded)['paging'] # this are used for take 'next' element in the dictionary\n",
    "\n",
    "    comment_count = 0\n",
    "    for count in data:\n",
    "        comment_count += 1\n",
    "\n",
    "    #count comments\n",
    "    add_num_comments(comment_count)\n",
    "\n",
    "    for key, value in next_post.iteritems() :\n",
    "        if key==\"next\":\n",
    "            scr_data = scrape_all_comments_from_post_id(value)\n",
    "\n",
    "    return data + scr_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'credentials.txt',\n",
       " 'facebook_scrapping.ipynb',\n",
       " 'FB_Web_scraping.ipynb',\n",
       " 'posts.csv',\n",
       " 'README.md',\n",
       " 'scraper.py',\n",
       " 'text.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_n_v = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    if filename.endswith(\".next_value\"):\n",
    "        filename_n_v.append(filename)\n",
    "\n",
    "\n",
    "num_page = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request token\n",
      "fresh access token: 1279153855620167|BPgJGoHxdsQI7NPUVNdPwFAlLHE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Request token\")\n",
    "#new access_token\n",
    "access_token_request = request_until_succeed(\"https://graph.facebook.com/v2.11/oauth/access_token?client_id=\" + app_id + \"&client_secret=\" + app_secret + \"&grant_type=client_credentials\")\n",
    "access_token = json.loads(access_token_request)[\"access_token\"] #!type unicode!\n",
    "print(\"fresh access token: \" + access_token + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://graph.facebook.com/v2.11/\"+ page_id +\"/posts/1311167095711069?__tn__=H-R\" + access_token + \"&limit=25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping's posts phase start...\n",
      "\n",
      "HTTP Error 400: Bad Request\n",
      "Error for URL https://graph.facebook.com/v2.11/laanews/posts/1311167095711069?__tn__=H-R1279153855620167|BPgJGoHxdsQI7NPUVNdPwFAlLHE&limit=25: 2020-05-04 10:10:50.092775\n",
      "Retrying.\n",
      "HTTP Error 400: Bad Request\n",
      "Error for URL https://graph.facebook.com/v2.11/laanews/posts/1311167095711069?__tn__=H-R1279153855620167|BPgJGoHxdsQI7NPUVNdPwFAlLHE&limit=25: 2020-05-04 10:10:55.525875\n",
      "Retrying.\n",
      "HTTP Error 400: Bad Request\n",
      "Error for URL https://graph.facebook.com/v2.11/laanews/posts/1311167095711069?__tn__=H-R1279153855620167|BPgJGoHxdsQI7NPUVNdPwFAlLHE&limit=25: 2020-05-04 10:11:00.834175\n",
      "Retrying.\n",
      "HTTP Error 400: Bad Request\n",
      "Error for URL https://graph.facebook.com/v2.11/laanews/posts/1311167095711069?__tn__=H-R1279153855620167|BPgJGoHxdsQI7NPUVNdPwFAlLHE&limit=25: 2020-05-04 10:11:06.270916\n",
      "Retrying.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cfef52ce0ec3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 1.next_value = i post che vanno da 26 a 50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# 2.next_value = i post che vanno da 51 a 75 etc...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mscrape_all_posts_in_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nScraping's posts phase stop...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7c382c7ec402>\u001b[0m in \u001b[0;36mscrape_all_posts_in_page\u001b[1;34m(url, num_page)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscrape_all_posts_in_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mjson_downloaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest_until_succeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_downloaded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Json(casted in dictionary) data from our request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mnext_post\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_downloaded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'paging'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# this are used for take 'next' element in the dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7c382c7ec402>\u001b[0m in \u001b[0;36mrequest_until_succeed\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1360\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1052\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrape_starttime = datetime.datetime.now()\n",
    "# start scraping's post phase\n",
    "print(\"Scraping's posts phase start...\\n\")\n",
    "\n",
    "# start from begin\n",
    "# scrape_first_posts_in_page(page_id, access_token)\n",
    "\n",
    "# start from a block's posts\n",
    "# files with next_value extension are:\n",
    "# 1.next_value = i post che vanno da 26 a 50\n",
    "# 2.next_value = i post che vanno da 51 a 75 etc...\n",
    "scrape_all_posts_in_page(url, num_page)\n",
    "\n",
    "print(\"\\nScraping's posts phase stop...\")\n",
    "\n",
    "print(\"\\nDone!\\n{} Comments Processed in {}\".format(\n",
    "        num_processed, datetime.datetime.now() - scrape_starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/3c/2e2d71aeb28ee73ecaf12b545542b082ca81c8c091bb05028c52c42696ce/webdriver_manager-2.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests in c:\\users\\006872\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.22.0)\n",
      "Collecting crayons (from webdriver-manager)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/64/ab71c69db049a5f404f1f2c7627578f4b59aca55e6ad9d939721ce6466dd/crayons-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: configparser in c:\\users\\006872\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from webdriver-manager) (3.7.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\006872\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\006872\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\006872\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\006872\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\006872\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.1)\n",
      "Installing collected packages: crayons, webdriver-manager\n",
      "Successfully installed crayons-0.3.0 webdriver-manager-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
